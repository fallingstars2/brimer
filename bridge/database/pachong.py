from playwright.sync_api import sync_playwright, TimeoutError
import time
import os
from urllib.parse import urlparse

# ====== å‚æ•° ======
CHROME_PATH = "C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe"
START_URL = "https://www.bridgebase.com/v3/app/lv"
TARGET_PAGES = [
    "https://www.bridgebase.com/myhands/hands.php?tourney=90031-1752545161-&username=olafssonm",
    "https://www.bridgebase.com/myhands/hands.php?tourney=90031-1752545161-&username=Baloo_rus&from_login=0",
]
OUTPUT_DIR = "output"


# å¯é€‰ï¼šä»æ–‡ä»¶æ‰¹é‡åŠ è½½
def load_target_pages(filepath):
    with open(filepath, "r", encoding="utf-8") as f:
        lines = f.readlines()
    return [line.strip() for line in lines if line.strip()]


# ====== çˆ¬è™«é€»è¾‘ ======
def main():
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    with sync_playwright() as p:
        # å¯åŠ¨ Chromiumï¼ˆæœ‰å¤´æ¨¡å¼ï¼‰
        browser = p.chromium.launch(executable_path=CHROME_PATH, headless=False)
        context = browser.new_context()

        page = context.new_page()
        page.goto(START_URL)

        print("ğŸš© å·²æ‰“å¼€ BBO é¦–é¡µï¼Œå¦‚æœ‰éªŒè¯ç è¯·æ‰‹åŠ¨éªŒè¯ âœ…")
        input("ğŸ‘‰ éªŒè¯é€šè¿‡åæŒ‰å›è½¦ç»§ç»­ï¼š")

        # success_links = []

        for link in TARGET_PAGES:
            print(f"ğŸš€ æ­£åœ¨æŠ“å–ï¼š{link}")

            try:
                page.goto(link, timeout=30000)
                time.sleep(10)
                page.wait_for_load_state("networkidle")

            except TimeoutError:
                print(f"âŒ è·³è½¬è¶…æ—¶ï¼š{link}")
                continue

            # ä½¿ç”¨ tourney å‚æ•°ä½œä¸ºæ–‡ä»¶å
            filename_base = link.split("tourney=")[-1].split("&")[0]
            safe_filename = (
                filename_base.replace("/", "").replace(":", "").strip() or "index"
            )
            html_filename = os.path.join(OUTPUT_DIR, f"{safe_filename}.html")

            # txt_filename = os.path.join(OUTPUT_DIR, f"{filename_base}.txt")

            # ä¿å­˜å®Œæ•´ HTML
            with open(html_filename, "w", encoding="utf-8") as f_html:
                f_html.write(page.content())
            print(f"âœ”ï¸ å·²ä¿å­˜ HTMLï¼š{html_filename}")

            # # å°è¯•æå–ä¸»è¦å†…å®¹
            # content = ""
            # for selector in ["article", "main.page", "div.content__default"]:
            #     element = page.query_selector(selector)
            #     if element:
            #         content = element.inner_text()
            #         break
            #
            # if content:
            #     with open(txt_filename, "w", encoding="utf-8") as f_txt:
            #         f_txt.write(content)
            #     print(f"âœ”ï¸ å·²ä¿å­˜çº¯æ–‡æœ¬ï¼š{txt_filename}")
            #     success_links.append(link)
            # else:
            #     print(f"âš ï¸ æ²¡æ‰¾åˆ°ä¸»è¦å†…å®¹æ ‡ç­¾ï¼š{link}")

            time.sleep(2)
        # # ä¿å­˜æˆåŠŸæŠ“å–çš„é“¾æ¥
        # if success_links:
        #     with open(os.path.join(OUTPUT_DIR, "true_select_http.txt"), "a", encoding="utf-8") as f:
        #         for url in success_links:
        #             f.write(url + "\n")
        #     print(f"âœ… å·²ä¿å­˜ {len(success_links)} æ¡æœ‰æ•ˆé“¾æ¥åˆ° true_select_http.txt")
        # else:
        #     print("âŒ æ²¡æœ‰æŠ“åˆ°ä»»ä½•å†…å®¹ï¼")

        browser.close()


if __name__ == "__main__":
    main()
