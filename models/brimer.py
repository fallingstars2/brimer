import torch
from torch import nn
from dataset_briges import load_all
import numpy as np
import os

vocab, vocab_size, token2id, id2token, data_loader = load_all()  # å­—å…¸å¤§å°ä¸º30
batch_size = 4


def get_sinusoidal_positional_encoding(seq_len, d_model):
    pos_enc = torch.zeros(seq_len, d_model)
    position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)
    div_term = torch.exp(
        torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model)
    )

    pos_enc[:, 0::2] = torch.sin(position * div_term)
    pos_enc[:, 1::2] = torch.cos(position * div_term)
    return pos_enc  # shape: [seq_len, d_model]


# class Brimer(nn.Module):
#     def __init__(
#         self,
#         d_model=256,
#         max_len=335,
#         num_classes=30,
#         num_layers_encoder=6,
#         num_layers_decoder=1,
#         num_heads=4,
#         dim_feedforward=512,
#         dropout=0.02,  # ä¸æŠ‘åˆ¶
#         read_embedding=False,
#     ):
#         super().__init__()
#         self.embedding = nn.Embedding(vocab_size, d_model).to("cuda")
#         # Positional Encoding
#         self.positional_encoding = self._get_positional_encoding(max_len, d_model).to("cuda")
#         self.n_embed = nn.Parameter(torch.randn(28, d_model).to("cuda"))
#         self.e_embed = nn.Parameter(torch.randn(28, d_model).to("cuda"))
#         self.s_embed = nn.Parameter(torch.randn(28, d_model).to("cuda"))
#         self.w_embed = nn.Parameter(torch.randn(28, d_model).to("cuda"))
#         self.jiao_embed = nn.Parameter(torch.randn(45, d_model).to("cuda"))
#         self.chu_embed = nn.Parameter(torch.randn(156, d_model).to("cuda"))
#         # ä¸æ›´æ–°çš„å¤´éƒ¨ 3 ä¸ª + å°¾éƒ¨ 18 ä¸ªé›¶å‘é‡ï¼Œå…± (21, d_model)
#         self.register_buffer("head_zeros", torch.zeros(4, d_model).to("cuda").detach())  # ä¸å¯è®­ç»ƒ
#         self.register_buffer("zhuang_zeros", torch.zeros(18, d_model).to("cuda").detach())
#         self.bridge_embedding = torch.cat(
#             [
#                 self.head_zeros,
#                 self.n_embed,
#                 self.e_embed,
#                 self.s_embed,
#                 self.w_embed,
#                 self.zhuang_zeros,
#                 self.jiao_embed,
#                 self.chu_embed,
#             ],
#             dim=0,
#         ).unsqueeze(0)
#         if read_embedding:
#             self.load_all_embeddings()
#         # print(self.bridge_embedding.size(),self.positional_encoding.size())
#         self.bridge_embedding = self.bridge_embedding.to("cuda")
#         # Transformer Encoder Layer
#         encoder_layer = nn.TransformerEncoderLayer(
#             d_model=d_model,
#             nhead=num_heads,
#             dim_feedforward=dim_feedforward,
#             dropout=dropout,
#             batch_first=True,  # ä½¿ç”¨ [B, L, D] é¡ºåº
#         )
#         self.transformer_encoder = nn.TransformerEncoder(
#             encoder_layer, num_layers=num_layers_encoder
#         )
#         # æ–°å¢è§£ç å™¨éƒ¨åˆ†ï¼Œ4å±‚
#         # decoder_layer = nn.TransformerDecoderLayer(
#         #     d_model=d_model,
#         #     nhead=num_heads,
#         #     dim_feedforward=dim_feedforward,
#         #     dropout=dropout,
#         #     batch_first=True,
#         # )
#         # self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers_decoder)
#
#         # è¾“å‡ºåˆ†ç±»å¤´ï¼šå¯ä»¥æ˜¯çº¿æ€§ + softmaxï¼ˆå¤šåˆ†ç±»ï¼‰æˆ–çº¿æ€§ + sigmoidï¼ˆäºŒåˆ†ç±»ï¼‰
#         self.classes = nn.Linear(d_model, num_classes)  # ä¸“é—¨è§£ç å‰é¢çš„ä¸‰ä¸ªé¢„æµ‹
#
#     def _get_positional_encoding(self, seq_len, d_model):
#         # ç®€å•çš„å¯å­¦ä¹ ä½ç½®ç¼–ç 
#         pe_init = get_sinusoidal_positional_encoding(seq_len, d_model)
#         return nn.Parameter(pe_init.unsqueeze(0))
#
#     def save_all_embeddings(self, path="all_embeddings.pt"):
#         # æŠŠæ‰€æœ‰éœ€è¦ä¿å­˜çš„æƒé‡æ‰“åŒ…æˆtupleæˆ–dict
#         all_embedding = (
#             self.embedding.weight.data.cpu(),  # nn.Embeddingçš„æƒé‡
#             self.positional_encoding.data.cpu(),
#             self.bridge_embedding.data.cpu(),
#         )
#         torch.save(all_embedding, path)
#         print(f"æƒé‡ä¿å­˜åˆ° {path}")
#
#     def load_all_embeddings(self, path="all_embeddings.pt"):
#         all_embedding = torch.load(path)
#         self.embedding.weight.data.copy_(all_embedding[0])
#         self.positional_encoding.data.copy_(all_embedding[1])
#         self.bridge_embedding.data.copy_(all_embedding[2])
#         print(f"æƒé‡ä» {path} åŠ è½½å®Œæˆ")
#
#     @staticmethod
#     def tokens_to_ids(tokens, token2id):
#         return [token2id.get(tok) for tok in tokens]
#
#     @staticmethod
#     def ids_to_token(tokens, id2token):
#         return [id2token.get(tok) for tok in tokens]
#
#     def forward(self, x, pred_position=None):  # x: [B, 335, 256]
#         x = self.embedding(x)  # é¦–å…ˆè·å¾—åµŒå…¥è¡¨ç¤º
#         # åŠ ä¸Šä½ç½®ç¼–ç å’Œæ¡¥ç‰Œç¼–ç 
#         x = x + self.positional_encoding + self.bridge_embedding  # [B, 335, 256]
#         # ç¼–ç å™¨
#         encoder_output = self.transformer_encoder(x)  # [B, 335, 256]
#         # # åˆ†ç±»
#         out = self.classes(encoder_output)  # [B,335,num_classes]
#         return out
#
#     """
#     ç‰¹æ®Šå­—ç¬¦<mask>ä¸ºä¸çŸ¥é“çš„å­—æ®µï¼Œè®­ç»ƒæ—¶æœ‰ä¸€ä¸ªç›®æ ‡é¢„æµ‹ã€‚<None>ä¸ºå·²ç»æ²¡æœ‰çš„å­—æ®µï¼Œä¸éœ€è¦é¢„æµ‹ã€‚<cls>ä¸ºåˆ†ç±»ä»»åŠ¡çš„ç›®æ ‡ï¼Œè¿™é‡Œæœ‰ä¸‰ä¸ªï¼ˆè§’è‰²ï¼ŒèŠ±è‰²ï¼Œå¤§å°ï¼‰ã€‚
#     ä¸€ä¸ªBridgeItemåº”è¯¥å¯ä»¥å¯¼å‡º52ä¸ªè®­ç»ƒæ•°æ®ï¼ˆé¢„æµ‹æ¯ä¸€æ¬¡å‡ºç‰Œï¼Œå¦å¤–åœ¨é¢„æµ‹çš„åŒæ—¶å¢åŠ é¢„æµ‹å…¶ä»–äººæ‰‹ç‰Œçš„ä»»åŠ¡ï¼‰ã€‚
#     æœ€ç»ˆå¯¼å‡ºä¸ºList[list]æ•°æ®ï¼Œå¤–å±‚é•¿åº¦ä¸º52ï¼Œå†…å±‚é•¿åº¦åº”è¯¥ä¸º334ã€‚ä¿å­˜ä¸ºpklæ•°æ®ï¼Œæ–¹ä¾¿ä¹‹åè¯»å–ã€‚
#
#     åœ¨åç»­çš„å¤„ç†ä¸­åŠ å…¥é¢„æµ‹ä¸åŒä»»åŠ¡æ—¶çš„æç¤ºè¯<pre>å’Œ<cls>ã€‚æ‰€ä»¥åç»­çš„æ‰€æœ‰ç´¢å¼•å…¨éƒ¨+=1
#
#     æœ€ç»ˆç´¢å¼•0-2æ˜¯é¢„æµ‹ï¼Œ3 4-29 30 æ˜¯ç¬¬nçš„æ‰‹ç‰Œ 31 32-57 58 æ˜¯eçš„æ‰‹ç‰Œ
#     59 60-85 86æ˜¯sçš„æ‰‹ç‰Œ 87 88-113 114 æ˜¯wçš„æ‰‹ç‰Œ
#
#     115-116 117-132æ˜¯åº„å®¶
#     133-177 æ˜¯å«ç‰Œ
#
#     178-180 1è½®
#     181-183 2è½®
#     .....
#     331-333 13è½®
#     """


def extract_use_x_y(xs, labels):
    all_use_x = []
    all_use_y = []

    for x, label in zip(xs, labels):
        task_type = x[0].item()
        use_x_tensor = []
        use_y_tensor = []

        if task_type == 3:
            sub_label = x[134:179]
            indices = (sub_label == 1).nonzero(as_tuple=True)[0]
            if indices.numel() > 0:
                use_x = indices + 134
                use_y = use_x - 1
                use_x_tensor.append(use_x)
                use_y_tensor.append(use_y)

        elif task_type == 4:
            indices = (x == 1).nonzero(as_tuple=True)[0]
            if indices.numel() > 0:
                use_x = indices
                use_y = use_x - 1
                use_x_tensor.append(use_x)
                use_y_tensor.append(use_y)

        if use_x_tensor:  # ç¡®ä¿æœ‰å†…å®¹
            use_x_tensor[0] = torch.cat(
                [torch.tensor([1, 2, 3], dtype=torch.long).to("cuda"), use_x_tensor[0]]
            )
            use_y_tensor[0] = torch.cat(
                [use_y_tensor[0][-3:].detach().clone().to("cuda"), use_y_tensor[0]]
            )
            assert len(use_x_tensor) == len(use_y_tensor) and len(
                use_x_tensor[0]
            ) == len(use_y_tensor[0])
            all_use_x.append(use_x_tensor[0])
            all_use_y.append(use_y_tensor[0])
    return all_use_x, all_use_y


import torch.nn.functional as F


def brimer_loss(pred_logits, targets, alpha=1.0, beta=0.3):
    """
    pred_logits: Tensor of shape [N, C] â€” logits for N samples, C classes
    targets:     Tensor of shape [N] â€” int64 class indices
    alpha:       Weight for first 3 samples
    beta:        Weight for remaining samples
    """
    # äº¤å‰ç†µæŸå¤±ï¼ˆä¸å–å¹³å‡ï¼‰
    losses = F.cross_entropy(pred_logits, targets, reduction="none")  # [N]

    weights = torch.ones_like(losses) * beta
    weights[:3] = alpha  # å‰ä¸‰ä¸ªæ ·æœ¬èµ‹å€¼ä¸º alpha

    weighted_loss = (losses * weights).mean()
    return weighted_loss


# def get_custom_optimizer(model: Brimer, base_lr: float):
#     # ä½ç½®ç¼–ç ï¼ˆè™½ç„¶æ˜¯ register_bufferï¼Œè‹¥ä¸º nn.Parameter å°±èƒ½å­¦ä¹ ï¼‰
#     # ä½†è¿™é‡Œä½ çœŸæ­£å¸Œæœ›åŠ å¤§å­¦ä¹ ç‡çš„æ˜¯ bridge_embedding
#     groups = []
#     # ä½ç½®åµŒå…¥ï¼ˆbridge_embedding æ˜¯ç”± Parameter æ„å»ºçš„ï¼‰
#     groups.append(
#         {
#             "params": [
#                 param for name, param in model.named_parameters() if "embed" in name
#             ],
#             "lr": base_lr * 1.5,
#         }
#     )
#
#     # åˆ†ç±»å¤´
#     groups.append({"params": model.classes.parameters(), "lr": base_lr * 2.0})
#
#     # Transformer ç¼–ç å™¨å±‚ï¼Œä»å‰åˆ°åå­¦ä¹ ç‡é€’å‡
#     num_layers = len(model.transformer_encoder.layers)
#     for i, layer in enumerate(model.transformer_encoder.layers):
#         # æ¯”å¦‚ i = 0 ~ 5ï¼Œé å‰å±‚å­¦ä¹ ç‡é«˜
#         lr_scale = 1.5 - (i / (num_layers - 1))  # ä» 1.5 çº¿æ€§é™åˆ° 0.5
#         groups.append({"params": layer.parameters(), "lr": base_lr / lr_scale})
#
#     # å…¶ä»–æ®‹ä½™éƒ¨åˆ†ï¼ˆå¦‚ embedding å±‚ï¼‰
#     already_in = set()
#     for g in groups:
#         for p in g["params"]:
#             already_in.add(id(p))
#     rest = [p for p in model.parameters() if id(p) not in already_in]
#     if rest:
#         groups.append({"params": rest, "lr": base_lr})
#
#     return torch.optim.Adam(groups)


MODEL_PATH = "brimer_model.pt"
import matplotlib.pyplot as plt
from IPython.display import clear_output


def train_brimer(lr, epochs, brimer):
    optimizer = torch.optim.Adam(brimer.parameters(), lr=lr)
    all_losses = []

    total_steps = len(data_loader) * epochs
    warmup_steps = int(total_steps * 0.1)  # å‰10%ä¸ºwarmup
    scheduler = get_scheduler(optimizer, warmup_steps, total_steps)
    step = 0

    plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼
    for epoch in range(epochs):
        epoch_losses = []
        for xs, labels in data_loader:
            use_x, use_y = extract_use_x_y(xs, labels)
            result = brimer(xs)
            loss = 0
            for r, u, l, y in zip(result, use_x, labels, use_y):
                loss += brimer_loss(r[u], l[y])
            loss = loss / batch_size

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            scheduler.step()  # ğŸ‘ˆ æ¯ä¸€æ­¥æ›´æ–°å­¦ä¹ ç‡
            step += 1

            epoch_losses.append(loss.item())

        avg_loss = sum(epoch_losses) / len(epoch_losses)
        all_losses.append(avg_loss)
        # âœ… å¯è§†åŒ–ï¼šæ¯ä¸ª epoch æ›´æ–°ä¸€æ¬¡å›¾åƒ
        clear_output(wait=True)
        plt.clf()
        plt.title("Training Loss")
        plt.xlabel("Epochs")
        plt.ylabel("Avg Loss")
        plt.plot(all_losses, label="avg loss")
        plt.legend()
        plt.pause(0.01)

        print(
            f"[Epoch {epoch + 1}] Avg Loss: {sum(epoch_losses) / len(epoch_losses):.4f}"
        )

    # è®­ç»ƒå®Œæ¯•ä¿å­˜æ¨¡å‹
    torch.save(brimer.state_dict(), MODEL_PATH)
    print(f"Model saved to {MODEL_PATH}")
    # ä¿å­˜è®­ç»ƒæ›²çº¿å›¾åƒ
    plt.savefig("training_loss.png")

    plt.ioff()
    plt.show()


from torch.optim.lr_scheduler import LambdaLR
import math


def get_scheduler(optimizer, warmup_steps, total_steps):
    def lr_lambda(current_step):
        if current_step < warmup_steps:
            return float(current_step) / float(max(1, warmup_steps))
        progress = float(current_step - warmup_steps) / float(
            max(1, total_steps - warmup_steps)
        )
        return 0.5 * (1.0 + math.cos(math.pi * progress))  # Cosine decay

    return LambdaLR(optimizer, lr_lambda)


def show_brimer():
    from torchinfo import summary

    brimer = Brimer(read_embedding=False)
    brimer.eval()
    brimer = brimer.cuda()

    # ä»æ•°æ®åŠ è½½å™¨è·å–ä¸€ä¸ªæ ·æœ¬ batch
    for xs, labels in data_loader:
        xs = xs.cuda()  # ä¿è¯æ•°æ®ä¹Ÿåœ¨ GPU ä¸Š
        break  # åªå–ä¸€ç»„æ•°æ®ç”¨äº summary

    # å±•ç¤ºæ¨¡å‹ç»“æ„
    model_summary = summary(
        brimer,
        input_data=xs,
        col_names=["input_size", "output_size", "num_params", "params_percent"],
        depth=4,  # æ§åˆ¶æ˜¾ç¤ºå±‚çº§
        verbose=1,
    )

    # ä¿å­˜åˆ°æ–‡ä»¶
    with open("brimer_model_summary.txt", "w", encoding="utf-8") as f:
        f.write(str(model_summary))


if __name__ == "__main__":
    # show_brimer()
    
    from brimer_2 import Brimer2
    
    brimer = Brimer2(read_embedding=False)
    # å°è¯•åŠ è½½å·²æœ‰æ¨¡å‹
    if os.path.exists(MODEL_PATH):
        print(f"Loading model from {MODEL_PATH}")
        brimer.load_state_dict(torch.load(MODEL_PATH))
    brimer.train()
    brimer = brimer.cuda()
    lr = 1e-3
    epochs = 2
    train_brimer(lr=lr, epochs=epochs, brimer=brimer)

    # for xs, labels in data_loader:
    #     use_x,use_y = extract_use_x_y(xs,labels) # è·å¾—æœ€ç»ˆæ‹¿æ¥åšæŸå¤±å‡½æ•°çš„ç´¢å¼•ä½ç½®
    #     # print(brimer(x))
    #     result = brimer(xs)
    #     loss = 0
    #     for r,u,l,y in zip(result,use_x,labels,use_y):
    #         # print(r[u],"\n\n",l[y])
    #         loss += brimer_loss(r[u], l[y])
    #         # print(loss)
    #     loss = loss / batch_size
    #     print(f"loss: {loss}")
    #     break # å¯ä»¥æ­£å¸¸å‰å‘
    # torch.save(brimer.state_dict(), MODEL_PATH)